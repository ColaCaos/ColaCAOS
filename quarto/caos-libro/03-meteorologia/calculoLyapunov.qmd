---
format:
  html:
    math: katex
execute:
  enabled: true
  echo: false
---

# Predictibilidad de datos meteorológicos


El primer paso a la hora de estudiar el caos en el tiempo meteorológico es disponer de datos históricos de los principales parámetros del tiempo. Existe una excelente web llamada [OpenMeteo](https://open-meteo.com/en/docs) que proporciona datos históricos de observaciones y predicciones para cualquier localidad, y que además lo hace de forma gratuita en:

https://open-meteo.com/en/docs

Poniéndome manos a la obra, he descargado los datos históricos de Galapagar desde el año 1950. La serie histórica que devuelve la página web tiene este formato:

latitude,longitude,elevation,utc_offset_seconds,timezone,timezone_abbreviation  
40.597538,-4.0735474,885.0,7200,Europe/Berlin,GMT+2  

time,temperature_2m_mean (°C),precipitation_sum (mm),wind_speed_10m_mean (km/h)  
1950-06-07,20.7,0.50,13.1  
1950-06-08,18.4,2.30,14.4  
1950-06-09,18.6,3.10,10.0  
1950-06-10,18.6,3.90,7.8  
1950-06-11,18.8,0.50,11.2  
1950-06-12,17.0,0.00,9.0  
1950-06-13,18.9,0.20,7.2  
1950-06-14,21.1,0.00,8.0  
1950-06-15,20.2,0.00,12.8  

En segundo lugar, tenemos que saber qué hacer con estos datos. Después de varias búsquedas en ChatGPT y google encontré un artículo sencillo sobre cómo calcular el exponente de Lyapunov en datos meteorologicos. 

> **Referencia completa:** Özgür E. & Yılmaz M. U. (2022). Using Chaos Theory to Determine Average Prediction Times of Different Meteorological Variables: A Case Study in Sivas. *Int. J. Adv. Eng. Pure Sci.* 34(1):101–106.  


El artículo investiga cuánto tiempo, en promedio, pueden predecirse fiablemente tres series diarias (temperatura, velocidad del viento y humedad relativa desde el año 2006 hasta el 2010 para la estación de Sivas en Turquía) usando teoría del caos. 
Le pasé este artículo a chatGPT y le pedí que reprodujese los cálculos para mis datos de Galapagar. Una de las preguntas que me lanzó de vuelta chatGPT es que si quería usar los valores de los parámetros $m$ y $\tau$ que usaban en el estudio de la estación turca. Pedí de vuelta a ChatGPT que eran estos valores, pues al parecer jugaban un papel crítico a la hora de estimar el valor del exponente de Lyapunov.


## Explicación de $\tau$ y $m$

**Retraso $\tau$**  
El retraso $\tau$ indica cuántos pasos (días) “saltamos” entre cada coordenada al calcular el exponente de Lyapunov. En lugar de usar solo $x(t)$, usamos  
$$
\bigl(x(t),\,x(t+\tau),\,x(t+2\tau),\dots\bigr).
$$  
- Si $\tau$ es muy pequeño, $x(t)$ y $x(t+\tau)$ están muy correlacionados y aportan información casi redundante.  
- Si $\tau$ es muy grande, $x(t)$ y $x(t+\tau)$ pueden ser casi independientes y perder la conexión dinámica.  

El artículo turco revela que es óptimo trabajar con un valor de $\tau$ igual a 3 para la temperatura. Es decir, analizaremos el exponente de Lyapunov de la serie que nos da la temperatura en Galapagar cada tres días.

**Dimensión de embedding $m$**  
La dimensión $m$ es el número de valores escalonados que usamos para describir el estado del sistema:  
$$
\mathbf X(t)=\bigl(x(t),\,x(t+\tau),\,x(t+2\tau),\dots,x(t+(m-1)\tau)\bigr).
$$  

Es decir, el estado del sistema en un día, no es solamente el valor de la temperatura ese día, sino el valor de ese día más varios días anteriores. Pues bien, lo que necesitamos saber es cual es la dimensión óptima del estado del sistema. Si por ejemplo solo cojo un día, habrá muchos días que sean similares ya que habrá muchos casos en los que coincida la temperatura media para ese día. Sin embargo, esto es engañoso, ya que no se tiene en cuenta el estado pasado del sistema. No es lo mismo estar en un día a 15 grados de temperatura media después de haber pasado una ola de calor, que estar a 15 grados después de varios días de ola de frío. De acuerdo al artículo turco un valor de $m=12$ es óptimo. 

Con estos valores de $\tau$ y $m$ le pedí a ChatGPT que me calculase el exponente de Lyapunov de la serie de temperaturas de Galapagar. ChatGPT usa en este caso el mismo algoritmo que para el cálculo del exponente de Laypunov de las simulaciones del péndulo doble. Se trata de un algoritmo bastante complicado cuya comprensión se me escapa. Hay que tener en cuenta que todos estos cálculos los realizo a con el modelo 04-mini-high, que tiene una capacidad matemática muy superior a la esperada de un alumno de bachillerato, y que además es capaz de hacer los cálculos en un entorno interno de Python, y de plotear resultados.

## Exponente de Lyapunov para la serie de valores de temperatura

A continuación muestro todos los valores de temperatura que hemos sacado de la web open-meteo. Obviamente en la serie original vemos que hay un componente estacional muy fuerte. Le pedía ChatGPT que estimase la variación estacional y que la quitase de los datos, dándome la gráfica de temperatura desestacionalizada. En ella se ven las variaciones de temperatura como algo más aleatorio, ya que hemos quitado las componentes estacionales. No obstante se ve una ligera subida de temperaturas desde el año 1950 hasta el presente, coincidente con el aumento de temperaturas observado a nivel global en la Tierra. 

```{python}
import pandas as pd
import numpy as np
from numpy.linalg import lstsq
import matplotlib.pyplot as plt

import pandas as pd
import numpy as np
from numpy.linalg import lstsq
import matplotlib.pyplot as plt

# Cargar y preparar los datos desde 1950
df = pd.read_csv('Galapagar.csv', skiprows=3, parse_dates=['time'])
df = df.rename(columns={'temperature_2m_mean (°C)': 'temperature'})
df = df[df['time'] >= '1950-01-01'].reset_index(drop=True)
df['t'] = (df['time'] - df['time'].iloc[0]).dt.days
temps = df['temperature'].values

# Desestacionalización: tendencia lineal y dos armónicos de Fourier
P = 365.25
K = 2

# Ajuste de tendencia lineal
X_poly = np.vander(df['t'], 2)
beta_poly, *_ = lstsq(X_poly, temps, rcond=None)
trend = X_poly.dot(beta_poly)

# Ajuste de componentes estacionales
X_seasonal = np.column_stack(
    [np.sin(2*np.pi*k*df['t']/P) for k in range(1, K+1)] +
    [np.cos(2*np.pi*k*df['t']/P) for k in range(1, K+1)]
)
beta_seasonal, *_ = lstsq(X_seasonal, temps - trend, rcond=None)
seasonal = X_seasonal.dot(beta_seasonal)

# Serie desestacionalizada
deseasonalized = temps - seasonal

# Plot de la serie original
plt.figure(figsize=(6, 4))
plt.plot(df['time'], temps)
plt.title('Temperatura Original (1950–presente)')
plt.xlabel('Fecha')
plt.ylabel('Temperatura (°C)')
plt.tight_layout()
plt.show()

# Plot de la serie desestacionalizada
plt.figure(figsize=(6, 4))
plt.plot(df['time'], deseasonalized)
plt.title('Temperatura Desestacionalizada (1950–presente)')
plt.xlabel('Fecha')
plt.ylabel('Temperatura (°C)')
plt.tight_layout()
plt.show()

```

Como curiosidad, le pedía a ChatGPT que hiciese una regresión no lineal de orden 2 para ver como ha ido evolucionando la temperatura media en Galapagar desde 1950. 

```{python}
import pandas as pd
import numpy as np
from numpy.linalg import lstsq
import matplotlib.pyplot as plt

# Cargar datos
df = pd.read_csv('Galapagar.csv', skiprows=3, parse_dates=['time'])
df = df.rename(columns={'temperature_2m_mean (°C)': 'temperature'})
df = df[df['time'] >= '1950-01-01'].reset_index(drop=True)
df['t'] = (df['time'] - df['time'].iloc[0]).dt.days

# Desestacionalización (tendencia lineal + 2 armónicos)
P = 365.25
K = 2
temps = df['temperature'].values

# Tendencia lineal
X_poly1 = np.vander(df['t'], 2)
beta_poly1, *_ = lstsq(X_poly1, temps, rcond=None)
trend = X_poly1.dot(beta_poly1)

# Componente estacional
X_seasonal = np.column_stack(
    [np.sin(2*np.pi*k*df['t']/P) for k in range(1, K+1)] +
    [np.cos(2*np.pi*k*df['t']/P) for k in range(1, K+1)]
)
beta_seasonal, *_ = lstsq(X_seasonal, temps - trend, rcond=None)
seasonal = X_seasonal.dot(beta_seasonal)

# Serie desestacionalizada
y = temps - seasonal

# Preparar variable independiente en años
years = 1950 + df['t'] / 365.25

# Regresión cuadrática
coeffs = np.polyfit(years, y, deg=2)
fit_curve = np.polyval(coeffs, years)

# Gráfico
plt.figure(figsize=(6, 4))
plt.plot(df['time'], y, label='Desestacionalizada')
plt.plot(df['time'], fit_curve, label='Ajuste cuadrático', linewidth=2)
plt.title('Temperatura desestacionalizada con ajuste cuadrático')
plt.xlabel('Fecha')
plt.ylabel('Temperatura (°C)')
plt.legend()
plt.tight_layout()
plt.show()

```

La temperatura media desestacionalizada ha subido desde 1950 hasta 2025 aproximadamente $\Delta y = y(2025) - y(1950) \approx 2.23\ ^\circ\mathrm{C}$.  
La tasa media de incremento es $\displaystyle \frac{2.23\ ^\circ\mathrm{C}}{75\ \mathrm{años}} \approx 0.030\ ^\circ\mathrm{C}/\mathrm{año}$ (aproximadamente $0.3\ ^\circ\mathrm{C}/\mathrm{década}$). ¡Casi nada!!!!!

Volvamos al tajo. Ahora le pido a ChatGPT que me haga el cálculo del exponente de Lyapunov para estos datos de temperatura, usando el mismo procedimiento y parámetros que en el artículo de la estación de Turquía. El exponente de Lyapunov máximo calculado para la temperatura desestacionalizada es  
$$
\lambda_{\max} \approx 0.219\ \mathrm{día}^{-1}.
$$

### Horizonte de predictibilidad

Veamos en qué se traduce esta exponente de Lyapunov. Al ser positivo sabemos que indica que estamos ante un sistema caótico, y que los errores se amplificarán con el tiempo. Veamos cuando multiplicamos por 10 un error inicial de 0.1 grados centígrados:

$$
T = \frac{1}{\lambda_{\max}}\ln\Bigl(\frac{L}{\varepsilon}\Bigr)
  = \frac{1}{0.219}\ln(10) \approx 10.5\ \mathrm{días}.
$$

### Amplificación de un error inicial de 0.1 °C tras 15 días

Y ahora veamos de forma gráfica cómo se va amplificando el error inicial de 0.1 grados tras quince días. 

```{python}
import numpy as np
import matplotlib.pyplot as plt

# Parámetros
lambda_max = 0.219    # día⁻¹
delta0 = 0.1          # °C
t = np.linspace(0, 15, 151)
delta = delta0 * np.exp(lambda_max * t)

# Gráfico
plt.figure(figsize=(6,4))
plt.plot(t, delta)
plt.xlabel('Días')
plt.ylabel('Error (°C)')
plt.title('Amplificación de un error inicial de 0.1°C ($\lambda=0.219\\,\\mathrm{día}^{-1}$)')
plt.tight_layout()
plt.show()
```

Estos valores refuerzan las hipótesis iniciales con las que habíamos especulado. Pasadas dos semanas es muy difícil tener estimaciones precisas del tiempo meteorológico. 



## Exponente de Lyapunov para la serie de velocidad del viento

A continuación cargamos y desestacionalizamos los datos de velocidad del viento (1950–presente), mostramos la serie original y la desestacionalizada:

```{python}
import pandas as pd
import numpy as np
from numpy.linalg import lstsq
import matplotlib.pyplot as plt

# 1. Cargar y preparar datos de viento desde 1950
df = pd.read_csv('Galapagar.csv', skiprows=3, parse_dates=['time'])
df = df.rename(columns={'wind_speed_10m_mean (km/h)': 'wind_speed'})
df = df[df['time'] >= '1950-01-01'].reset_index(drop=True)
df['t'] = (df['time'] - df['time'].iloc[0]).dt.days
wind = df['wind_speed'].values

# 2. Desestacionalización: tendencia lineal + dos armónicos de Fourier
P = 365.25
K = 2

# Ajuste de tendencia lineal
X_poly = np.vander(df['t'], 2)
beta_poly, *_ = lstsq(X_poly, wind, rcond=None)
trend = X_poly.dot(beta_poly)

# Ajuste de componentes estacionales
X_seasonal = np.column_stack(
    [np.sin(2*np.pi*k*df['t']/P) for k in range(1, K+1)] +
    [np.cos(2*np.pi*k*df['t']/P) for k in range(1, K+1)]
)
beta_seasonal, *_ = lstsq(X_seasonal, wind - trend, rcond=None)
seasonal = X_seasonal.dot(beta_seasonal)

# Series
deseasonalized = wind - seasonal

# 3. Graficar original vs desestacionalizada
plt.figure(figsize=(6,4))
plt.plot(df['time'], wind, label='Original')
plt.plot(df['time'], deseasonalized, label='Desestacionalizada')
plt.title('Velocidad del viento (1950–presente)')
plt.xlabel('Fecha')
plt.ylabel('Velocidad (km/h)')
plt.legend()
plt.tight_layout()
plt.show()
```

En este caso no hay gran diferencia entre la componente desestacionalizada y sin desestacionalizar. 

### Exponente de Lyapunov

El exponente de Lyapunov máximo calculado para la serie de viento desestacionalizada (usando Wolf, $m=12$, $\tau=3$) es  
$$
\lambda_{\max} \approx 0.414\ \mathrm{día}^{-1}.
$$

### Horizonte de predictibilidad

Para un error inicial $\varepsilon = 1\ \mathrm{km/h}$ y un factor de crecimiento 10× ($L/\varepsilon=10$):  
$$
T = \frac{1}{\lambda_{\max}}\ln\Bigl(\frac{L}{\varepsilon}\Bigr)
  = \frac{1}{0.414}\ln(10)\approx5.6\ \mathrm{días}.
$$

### Amplificación de un error inicial de 1 km/h tras 15 días

```{python}
import numpy as np
import matplotlib.pyplot as plt

# Parámetros
lambda_max = 0.414    # día⁻¹
delta0 = 1          # km/h
t = np.linspace(0, 15, 151)
delta = delta0 * np.exp(lambda_max * t)

plt.figure(figsize=(6,4))
plt.plot(t, delta)
plt.xlabel('Días')
plt.ylabel('Error (km/h)')
plt.title('Amplificación de un error inicial de 1 km/h ($\lambda=0.414\\,\\mathrm{día}^{-1}$)')
plt.tight_layout()
plt.show()
```

### Comparación de la predictibilidad: viento vs temperatura {#sec-lyapunov}

En el caso de la temperatura desestacionalizada, obtuvimos un exponente de Lyapunov  
$$
\lambda_{\max}^{\rm temp}\approx0.219\ \mathrm{día}^{-1},
$$  
lo que da un horizonte de predictibilidad de  
$$
T_{\rm temp}
=\frac{1}{0.219}\ln(10)\approx10.5\ \mathrm{días}.
$$

Para la velocidad del viento desestacionalizada hallamos  
$$
\lambda_{\max}^{\rm viento}\approx0.414\ \mathrm{día}^{-1},
$$  
y por tanto  
$$
T_{\rm viento}
=\frac{1}{0.414}\ln(10)\approx5.6\ \mathrm{días}.
$$

Observamos que  
$$
T_{\rm viento}\approx\frac{1}{2}\,T_{\rm temp}.
$$  
Esto significa que **la serie de viento es más caótica**: su exponente de Lyapunov es casi el doble, y los errores iniciales se amplifican mucho más rápido.  

Varias razones explican esta diferencia:

- **Variabilidad a corto plazo**: la velocidad del viento está dominada por fenómenos de escala reducida (frentes, turbulencia, ráfagas) que inducen cambios bruscos.
- **Forzamientos estacionales débiles**: el ciclo anual aporta poca oscilación comparado con la temperatura, por lo que el viento muestra un comportamiento intrínsecamente más errático.


1. **¿Qué es un “forzamiento estacional”?**  
   Es la variación periódica y predecible que se repite cada año, debida al cambio de estación (más sol y calor en verano, menos en invierno).

2. **Temperatura vs. viento**  
   - **Temperatura**: el rango típico entre verano e invierno puede ser de $\pm10\ ^\circ\mathrm{C}$ o más. Es decir, el ciclo anual supone una parte muy importante de la variabilidad total.  
   - **Viento**: la velocidad media cambia solo unos $\pm2\ \mathrm{km/h}$ a lo largo del año. Esa “señal” anual es pequeña comparada con las oscilaciones diarias o las rachas impredecibles.

3. **Efecto al desestacionalizar**  
   - Al quitar la estacionalidad de la temperatura, reducimos mucho la amplitud de la serie y “dejamos ver” las fluctuaciones reales.  
   - Al hacer lo mismo con el viento, casi no cambiamos nada: la mayor parte de la variabilidad ya venía de eventos de corto plazo, no del ciclo anual.


- **Implicaciones prácticas**: mientras que las predicciones de temperatura pueden ser útiles hasta unos 10 días, las de viento pierden precisión ya a los 5–6 días, reflejo de su carácter más caótico.

